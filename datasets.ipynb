{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples of dataset:\n",
    "* [torchvision](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchaudio\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "from functools import reduce, partial\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Cache:\n",
    "    def __init__(self, generator, location):\n",
    "        self.generator = generator\n",
    "        self.location = location\n",
    "\n",
    "        self._id = id(self)\n",
    "        self._cache = []\n",
    "        self._internal_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._internal_index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._internal_index < len(self):\n",
    "            item = self[self._internal_index]\n",
    "        else:\n",
    "            item = next(self.generator)\n",
    "        \n",
    "            file = str(self._id) + \"-\" + str(len(self))\n",
    "            file = os.path.join(self.location, file)\n",
    "            self._cache.append(file)\n",
    "        \n",
    "            os.makedirs(self.location, exist_ok=True)\n",
    "            with open(file, 'wb') as file:\n",
    "                pickle.dump(item, file)\n",
    "\n",
    "        self._internal_index += 1\n",
    "        return item\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file = self._cache[index]\n",
    "        with open(file, 'rb') as file:\n",
    "            item = pickle.load(file)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return length of cache\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(0,2):\n",
    "        yield i\n",
    "        \n",
    "cache = Cache(gen(), \"tmp/\")\n",
    "\n",
    "for c in cache:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    return lambda x: reduce(lambda f, g: g(f), list(funcs), x)\n",
    "\n",
    "def download(urls, root_path):\n",
    "    for url, folder in urls:\n",
    "        # torchvision.datasets.utils.download_url(url, root_path)\n",
    "        file = os.path.join(root_path, os.path.basename(url))\n",
    "        yield file, folder\n",
    "    \n",
    "def extract(files):\n",
    "    for file, folder in files:\n",
    "        # torchvision.datasets.utils.extract_archive(file)\n",
    "        path = os.path.dirname(file)\n",
    "        path = os.path.join(path, folder)\n",
    "        yield path\n",
    "            \n",
    "def walk(paths, extension):\n",
    "    for path in paths:\n",
    "        for dp, dn, fn in os.walk(path):\n",
    "            for f in fn:\n",
    "                if extension in f:\n",
    "                    yield path, f\n",
    "\n",
    "def shuffle(generator):\n",
    "    # Need to load the whole list in memory\n",
    "    generator = list(generator)\n",
    "    # print(len(generator))\n",
    "    random.shuffle(generator)\n",
    "    for g in generator:\n",
    "        yield g\n",
    "\n",
    "def filtering(fileids, reference):\n",
    "    \n",
    "    path_old = \"\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        \n",
    "        if path != path_old:\n",
    "            # Check if same path to avoid reloading the file constantly\n",
    "            ref = os.path.join(path, reference)\n",
    "            with open(ref) as ref:\n",
    "                r = \"\".join(ref.readlines())\n",
    "\n",
    "        # It would be more efficient to loop through the reference file instead\n",
    "        if fileid in r:\n",
    "            yield path, fileid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1', '1', '1', '1', '1', '1', '1', '1'],\n",
       " tensor([[-3.0518e-05,  6.1035e-05,  3.0518e-05,  ...,  3.9673e-04,\n",
       "           5.4932e-04,  9.1553e-04]]),\n",
       " 8000)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_yesno(fileids):\n",
    "    extension = \".wav\"\n",
    "    for path, fileid in fileids:\n",
    "        file = os.path.join(path, fileid)\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "        label = os.path.basename(fileid).split(\".\")[0].split(\"_\")\n",
    "    \n",
    "        yield label, waveform, sample_rate\n",
    "        \n",
    "\n",
    "def YESNO(root):\n",
    "    \n",
    "    url = [\n",
    "        (\"http://www.openslr.org/resources/1/waves_yesno.tar.gz\", \"waves_yesno\")\n",
    "    ]\n",
    "     \n",
    "    pipeline = compose(\n",
    "        partial(download, root_path=root),\n",
    "        extract,\n",
    "        partial(walk, extension=\".wav\"),\n",
    "        shuffle,\n",
    "        load_yesno,\n",
    "    )\n",
    "    \n",
    "    return Cache(pipeline(url), \"tmp/\")\n",
    "\n",
    "\n",
    "data = YESNO(\"/Users/vincentqb/yesnotest\")\n",
    "\n",
    "next(data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p282_342',\n",
       " 'In addition, it was in breach of natural justice.\\n',\n",
       " tensor([[-0.0035, -0.0047, -0.0041,  ..., -0.0043, -0.0050, -0.0036]]),\n",
       " 48000)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_vctk(fileids):\n",
    "    txt_folder = \"txt\"\n",
    "    txt_extension = \".txt\"\n",
    "    \n",
    "    audio_folder = \"wav48\"\n",
    "    audio_extension = \".wav\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        \n",
    "        fileid = os.path.basename(fileid).split(\".\")[0]\n",
    "        folder = fileid.split(\"_\")[0]\n",
    "        txt_file = os.path.join(path, txt_folder, folder, fileid + txt_extension)        \n",
    "        audio_file = os.path.join(path, audio_folder, folder, fileid + audio_extension)        \n",
    "        \n",
    "        try:\n",
    "            with open(txt_file) as txt_file:\n",
    "                content = txt_file.readlines()[0]\n",
    "        except FileNotFoundError:\n",
    "            warn(\"Translation not found for {}\".format(audio_file))\n",
    "            # warn(\"File not found: {}\".format(txt_file))\n",
    "            continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        \n",
    "        yield fileid, content, waveform, sample_rate\n",
    "        \n",
    "        \n",
    "def VCTK(root):\n",
    "    \n",
    "    url = [\n",
    "        ('http://homepages.inf.ed.ac.uk/jyamagis/release/VCTK-Corpus.tar.gz', \"VCTK-Corpus/\")\n",
    "    ]\n",
    "    \n",
    "    pipeline = compose(\n",
    "        partial(download, root_path=root),\n",
    "        extract,\n",
    "        partial(walk, extension=\".wav\"),\n",
    "        shuffle,\n",
    "        load_vctk,\n",
    "    )\n",
    "    \n",
    "    return Cache(pipeline(url), \"tmp/\")\n",
    "\n",
    "\n",
    "data = VCTK(\"/Users/vincentqb/vctktest/\")\n",
    "\n",
    "next(data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('7976-105575-0003',\n",
       " tensor([[ 3.0518e-05, -3.0518e-05,  0.0000e+00,  ...,  2.4414e-04,\n",
       "           2.4414e-04,  1.2207e-04]]),\n",
       " 16000,\n",
       " \"THERE WERE NO BREASTWORKS YET THAT ONE LITTLE BRIGADE OF HAMILTON'S DIVISION STOOD THERE IN THE OPEN AND REPULSED ASSAULT AFTER ASSAULT\")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_librispeech(fileids):\n",
    "    text_extension = \".trans.txt\"\n",
    "    audio_extension = \".flac\"\n",
    "    for data_path, fileid in fileids:\n",
    "        fileid = os.path.basename(fileid).split(\".\")[0]\n",
    "        folder1, folder2, file = fileid.split(\"-\")\n",
    "        file_text = folder1 + \"-\" + folder2 + text_extension\n",
    "        file_text = os.path.join(data_path, folder1, folder2, file_text)\n",
    "        file_audio = folder1 + \"-\"+ folder2 + \"-\" + file + audio_extension\n",
    "        file_audio = os.path.join(data_path, folder1, folder2, file_audio)\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "        found = False\n",
    "        for line in open(file_text):\n",
    "            fileid_text, content = line.strip().split(\" \", 1)\n",
    "            if fileid == fileid_text:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            from warnings import warn\n",
    "            warn(\"Translation not found for {}.\".format(fileid))\n",
    "            continue\n",
    "\n",
    "        yield fileid, waveform, sample_rate, content\n",
    "        \n",
    "\n",
    "def LIBRISPEECH(root, selection=\"dev-clean\"):\n",
    "    \n",
    "    # http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "    # http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "    # http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "    selections = [\n",
    "        \"dev-clean\",\n",
    "        \"test-clean\",\n",
    "        \"test-other\",\n",
    "        \"train-clean-100\",\n",
    "        \"train-clean-360\",\n",
    "        \"train-other-500\"\n",
    "    ]\n",
    "        \n",
    "    base = \"http://www.openslr.org/resources/12/\"\n",
    "    url = [\n",
    "        (os.path.join(base, selection + \".tar.gz\"), os.path.join(\"LibriSpeech\", selection))\n",
    "    ]\n",
    "     \n",
    "    pipeline = compose(\n",
    "        partial(download, root_path=root),\n",
    "        extract,\n",
    "        partial(walk, extension=\".flac\"),\n",
    "        shuffle,\n",
    "        load_librispeech,\n",
    "    )\n",
    "\n",
    "    return Cache(pipeline(url), \"tmp/\")\n",
    "\n",
    "\n",
    "data = LIBRISPEECH(\"/Users/vincentqb/librispeechtest/\")\n",
    "\n",
    "next(data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bb10e83bdf015da18144f427509d8cb56cfa4884527dc0cb3da927c845b733e48d3c451ae9538723b747fd6e34b15a863635e71b09a7611b7484f09e4cd109be',\n",
       " 'common_voice_tt_17733179.mp3',\n",
       " 'Белгән мең бәладән котылган.',\n",
       " '2',\n",
       " '0',\n",
       " 'thirties',\n",
       " 'male',\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.8723e-05,\n",
       "          -3.7115e-05, -5.9720e-05]]),\n",
       " 48000]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_commonvoice(fileids, tsv):\n",
    "\n",
    "    for path, fileid in fileids:\n",
    "        filename = os.path.join(path, \"clips\", fileid)\n",
    "        tsv = os.path.join(path, tsv)\n",
    "        \n",
    "        found = False\n",
    "        for line in open(tsv):\n",
    "            if fileid in line:\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            continue\n",
    "\n",
    "        output = torchaudio.load(filename)    \n",
    "        line.extend(output)\n",
    "        yield line\n",
    "        \n",
    "\n",
    "def COMMONVOICE(root, language=\"tatar\", tsv=\"train.tsv\"):\n",
    "    web = \"https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/\"\n",
    "\n",
    "    languages = {\n",
    "        \"tatar\": \"tt\",\n",
    "        \"english\": \"en\",\n",
    "        \"german\": \"de\",\n",
    "        \"french\": \"fr\",\n",
    "        \"welsh\": \"cy\",\n",
    "        \"breton\": \"br\",\n",
    "        \"chuvash\": \"cv\",\n",
    "        \"turkish\": \"tr\",\n",
    "        \"kyrgyz\": \"ky\",\n",
    "        \"irish\": \"ga-IE\",\n",
    "        \"kabyle\": \"kab\",\n",
    "        \"catalan\": \"ca\",\n",
    "        \"taiwanese\": \"zh-TW\",\n",
    "        \"slovenian\": \"sl\",\n",
    "        \"italian\": \"it\",\n",
    "        \"dutch\": \"nl\",\n",
    "        \"hakha chin\": \"cnh\",\n",
    "        \"esperanto\": \"eo\",\n",
    "        \"estonian\": \"et\",\n",
    "        \"persian\": \"fa\",\n",
    "        \"basque\": \"eu\",\n",
    "        \"spanish\": \"es\",\n",
    "        \"chinese\": \"zh-CN\",\n",
    "        \"mongolian\": \"mn\",\n",
    "        \"sakha\": \"sah\",\n",
    "        \"dhivehi\": \"dv\",\n",
    "        \"kinyarwanda\": \"rw\",\n",
    "        \"swedish\": \"sv-SE\",\n",
    "        \"russian\": \"ru\",\n",
    "    }\n",
    "\n",
    "    url = web + languages[language] + \".tar.gz\"\n",
    "    url = [(url, \"\")]\n",
    "     \n",
    "    pipeline = compose(\n",
    "        partial(download, root_path=root),\n",
    "        extract,\n",
    "        partial(walk, extension=\".mp3\"),\n",
    "        # partial(filtering, reference=tsv),\n",
    "        shuffle,\n",
    "        partial(load_commonvoice, tsv=tsv),\n",
    "    )\n",
    "    \n",
    "    return Cache(pipeline(url), \"tmp/\")\n",
    "\n",
    "\n",
    "data = COMMONVOICE(\"/Users/vincentqb/commonvoicetest/\")\n",
    "\n",
    "next(data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yesno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yesno\n",
    "# filename = \"waves_yesno.tar.gz\"\n",
    "# url = \"http://www.openslr.org/resources/1/\" + filename\n",
    "\n",
    "url = \"http://www.openslr.org/resources/1/waves_yesno.tar.gz\"\n",
    "filename = os.path.basename(url)\n",
    "root = \"/Users/vincentqb/yesnotest/\"\n",
    "\n",
    "inpath = root + filename\n",
    "dset_abs_path = root + \"waves_yesno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.datasets.utils.download_url(url, root)\n",
    "\n",
    "# torchvision.datasets.utils.extract_archive(inpath, root)  # FIXME no extraction with root\n",
    "torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_yesno(root):\n",
    "    for f in os.listdir(root):\n",
    "        if \".wav\" in f:\n",
    "            yield os.path.join(root, f)\n",
    "\n",
    "def load_yesno(file_generator):\n",
    "    for file in file_generator:\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "        label = os.path.basename(file).split(\".\", 1)[0].split(\"_\")\n",
    "    \n",
    "        yield label, waveform, sample_rate\n",
    "\n",
    "g = load_yesno(iterate_yesno(dset_abs_path))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def iterate_yesno(dset_abs_path):\n",
    "    for f in os.listdir(dset_abs_path):\n",
    "        if \".wav\" not in f:\n",
    "            continue\n",
    "    \n",
    "        full_path = os.path.join(dset_abs_path, f)\n",
    "        waveform, sample_rate = torchaudio.load(full_path)\n",
    "        label = os.path.basename(f).split(\".\", 1)[0].split(\"_\")\n",
    "        l = sig.size(1)\n",
    "    \n",
    "        yield label, waveform, sample_rate, l\n",
    "\n",
    "g = iterate_yesno(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vctk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"DS_10283_2651.zip\"\n",
    "filename2 = \"VCTK-Corpus.zip\"\n",
    "url = \"http://datashare.is.ed.ac.uk/download/\" + filename1\n",
    "root = \"/Users/vincentqb/vctktest/\"\n",
    "\n",
    "inpath1 = root + filename1\n",
    "inpath2 = root + filename2\n",
    "dset_abs_path = root + \"VCTK-Corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "\n",
    "# torchvision.datasets.utils.extract_archive(inpath, root)  # FIXME no extraction with root\n",
    "torchvision.datasets.utils.extract_archive(inpath1)\n",
    "torchvision.datasets.utils.extract_archive(inpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_vctk(root):\n",
    "    folder_txt = os.path.join(root, \"txt/\")\n",
    "    folder_wav = os.path.join(root, \"wav48/\")\n",
    "    \n",
    "    for dp, _, fn in os.walk(folder_txt):\n",
    "        for f in fn:\n",
    "            if \".txt\" in f:\n",
    "                file_txt = os.path.join(dp, f)\n",
    "                base = os.path.basename(file_txt).split(\".\", 1)[0]\n",
    "                folder = base.split(\"_\")[0]\n",
    "                file_audio = os.path.join(folder_wav, folder, base) + \".wav\"\n",
    "            \n",
    "                yield base, file_txt, file_audio\n",
    "\n",
    "\n",
    "def load_vctk(file_generator):\n",
    "    for base, file_txt, file_audio in file_generator:\n",
    "            \n",
    "        with open(file_txt) as file_txt:\n",
    "            content = file_txt.readlines()[0]\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "\n",
    "        yield base, content, waveform, sample_rate\n",
    "\n",
    "\n",
    "g = load_vctk(iterate_vctk(dset_abs_path))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def iterate_vctk(root):\n",
    "    folder_txt = os.path.join(root, \"txt/\")\n",
    "    folder_wav = os.path.join(root, \"wav48/\")\n",
    "    \n",
    "    for dp, _, fn in os.walk(folder_txt):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "            \n",
    "            file_txt = os.path.join(dp, f)\n",
    "            with open(file_txt) as file_txt:\n",
    "                content = file_txt.readlines()[0]\n",
    "\n",
    "            \n",
    "            base = os.path.basename(f).split(\".\", 1)[0]\n",
    "            folder = base.split(\"_\")[0]\n",
    "            file_audio = os.path.join(folder_wav, folder, base) + \".wav\"\n",
    "            waveform, sample_rate = torchaudio.load(file_audio)\n",
    "            \n",
    "            yield base, content, waveform, sample_rate\n",
    "\n",
    "g = iterate_vctk(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.openslr.org/12\n",
    "# http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "class LibriSpeech(object):\n",
    "\n",
    "    url_base = \"http://www.openslr.org/resources/12/\"\n",
    "    url_extension = \".tar.gz\"\n",
    "    audio_extension = \".flac\"\n",
    "    text_extension = \".trans.txt\"\n",
    "\n",
    "    _selection = [\n",
    "        \"dev-clean\",\n",
    "        \"test-clean\",\n",
    "        \"test-other\",\n",
    "        \"train-clean-100\",\n",
    "        \"train-clean-360\",\n",
    "        \"train-other-500\"\n",
    "    ]\n",
    "    \n",
    "    in_archive_folder = \"LibriSpeech\"\n",
    "\n",
    "    def __init__(self, selection, root_path, extracted=True, shuffle=False):\n",
    "\n",
    "        if selection not in self._selection:\n",
    "            raise ValueError\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.selection = selection\n",
    "        self.extracted = extracted\n",
    "\n",
    "        self.url = self.url_base + self.selection + self.url_extension\n",
    "        \n",
    "        if shuffle:\n",
    "            c = compose(self.download, self.extract, self.walk, self.shuffle, self.load)\n",
    "        else:\n",
    "            c = compose(self.download, self.extract, self.walk, self.load)\n",
    "\n",
    "        # Initialize here or in __iter__\n",
    "        self._iterator = c([selection])\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self._iterator.__next__()\n",
    "        \n",
    "    def download(self, selections):\n",
    "        for selection in selections:\n",
    "            url = os.path.join(self.url_base, selection + self.url_extension)\n",
    "            # torchvision.datasets.utils.download_url(url, self.root_path)\n",
    "            yield selection\n",
    "    \n",
    "    def extract(self, selections):\n",
    "        for selection in selections:\n",
    "            archive_path = os.path.join(self.root_path, selection + self.url_extension)\n",
    "            # torchvision.datasets.utils.extract_archive(archive_path)\n",
    "            yield os.path.join(self.root_path, self.in_archive_folder, selection)\n",
    "\n",
    "    def walk(self, paths):\n",
    "        for path in paths:\n",
    "            for dp, dn, fn in os.walk(path):\n",
    "                for f in fn:\n",
    "                    if self.audio_extension in f:\n",
    "                        yield path, os.path.basename(f).split(\".\")[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle(generator):\n",
    "        generator = list(generator)\n",
    "        random.shuffle(generator)\n",
    "        for g in generator:\n",
    "            yield g\n",
    "        \n",
    "    def load(self, fileids):\n",
    "        for data_path, fileid in fileids:\n",
    "            folder1, folder2, file = fileid.split(\"-\")\n",
    "            file_text = folder1 + \"-\" + folder2 + self.text_extension\n",
    "            file_text = os.path.join(data_path, folder1, folder2, file_text)\n",
    "            file_audio = folder1 + \"-\"+ folder2 + \"-\" + file + self.audio_extension\n",
    "            filase_audio = os.path.join(data_path, folder1, folder2, file_audio)\n",
    "            waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "            found = False\n",
    "            for line in open(file_text):\n",
    "                fileid_text, content = line.strip().split(\" \", 1)\n",
    "                if fileid == fileid_text:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                warn(\"Audio file without translation: {}.\".format(fileid))\n",
    "                continue\n",
    "\n",
    "            yield fileid, waveform, sample_rate, content\n",
    "\n",
    "\n",
    "ls = LibriSpeech(\"dev-clean\", \"/Users/vincentqb/librispeechtest/\")\n",
    "next(ls) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# librispeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.openslr.org/12\n",
    "# http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "\n",
    "url_base = \"http://www.openslr.org/resources/12/\"\n",
    "url_extension = \".tar.gz\"\n",
    "\n",
    "selection = [\n",
    "    \"dev-clean\",\n",
    "    \"test-clean\",\n",
    "    \"test-clean\",\n",
    "    \"test-other\",\n",
    "    \"train-clean-100\",\n",
    "    \"train-clean-360\",\n",
    "    \"train-other-500\"\n",
    "]\n",
    "\n",
    "url = url_base + selection[0] + url_extension\n",
    "root = \"/Users/vincentqb/librispeechtest/\"\n",
    "\n",
    "filename = os.path.basename(url)\n",
    "inpath = root + filename\n",
    "\n",
    "base = filename.split(\".\")[0]\n",
    "dset_abs_path = root + \"LibriSpeech/\" + base + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "# torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iterate_librispeech(root):\n",
    "    for dp, dn, fn in os.walk(root):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "        \n",
    "            fp = os.path.join(dp, f)\n",
    "            for line in open(fp):\n",
    "                fileid, content = line.strip().split(\" \", 1)\n",
    "                audio = os.path.join(dp, fileid) + \".flac\"\n",
    "                waveform, sample_rate = torchaudio.load(audio)\n",
    "                yield fileid, waveform, sample_rate, content\n",
    "\n",
    "g = iterate_librispeech(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_librispeech(root):\n",
    "    for dp, dn, fn in os.walk(root):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "        \n",
    "            fp = os.path.join(dp, f)\n",
    "            for line in open(fp):\n",
    "                fileid, _ = line.strip().split(\" \", 1)\n",
    "                yield root, fileid\n",
    "\n",
    "def load_librispeech(file_generator):\n",
    "    for root, fileid in file_generator:\n",
    "        folder1, folder2, file = fileid.split(\"-\")\n",
    "        file_text = os.path.join(root, folder1, folder2, folder1) + \"-\" + folder2 + \".trans.txt\"\n",
    "        file_audio = os.path.join(root, folder1, folder2, folder1) + \"-\" + folder2 + \"-\" + file + \".flac\"\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "        found = False\n",
    "        for line in open(file_text):\n",
    "            fileid_text, content = line.strip().split(\" \", 1)\n",
    "            if fileid == fileid_text:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            raise Error\n",
    "\n",
    "        yield fileid, waveform, sample_rate, content\n",
    "\n",
    "g = load_librispeech(iterate_librispeech(dset_abs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommonVoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = \"https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/\"\n",
    "\n",
    "languages = {\n",
    "    \"tatar\": \"tt\",\n",
    "    \"english\": \"en\",\n",
    "    \"german\": \"de\",\n",
    "    \"french\": \"fr\",\n",
    "    \"welsh\": \"cy\",\n",
    "    \"breton\": \"br\",\n",
    "    \"chuvash\": \"cv\",\n",
    "    \"turkish\": \"tr\",\n",
    "    \"kyrgyz\": \"ky\",\n",
    "    \"irish\": \"ga-IE\",\n",
    "    \"kabyle\": \"kab\",\n",
    "    \"catalan\": \"ca\",\n",
    "    \"taiwanese\": \"zh-TW\",\n",
    "    \"slovenian\": \"sl\",\n",
    "    \"italian\": \"it\",\n",
    "    \"dutch\": \"nl\",\n",
    "    \"hakha chin\": \"cnh\",\n",
    "    \"esperanto\": \"eo\",\n",
    "    \"estonian\": \"et\",\n",
    "    \"persian\": \"fa\",\n",
    "    \"basque\": \"eu\",\n",
    "    \"spanish\": \"es\",\n",
    "    \"chinese\": \"zh-CN\",\n",
    "    \"mongolian\": \"mn\",\n",
    "    \"sakha\": \"sah\",\n",
    "    \"dhivehi\": \"dv\",\n",
    "    \"kinyarwanda\": \"rw\",\n",
    "    \"swedish\": \"sv-SE\",\n",
    "    \"russian\": \"ru\",\n",
    "}\n",
    "\n",
    "url = web + languages[\"tatar\"] + \".tar.gz\"\n",
    "root = \"/Users/vincentqb/commonvoicetest/\"\n",
    "\n",
    "filename = os.path.basename(url)\n",
    "inpath = root + filename\n",
    "\n",
    "base = filename.split(\".\")[0]\n",
    "dset_abs_path = root\n",
    "tsv = \"train.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "# torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_commonvoice(root, tsv):\n",
    "    tsv = os.path.join(root, tsv)\n",
    "    with open(tsv) as tsv:\n",
    "        \n",
    "        header = next(tsv)\n",
    "        header = header.strip().split(\"\\t\")\n",
    "        \n",
    "        for line in tsv:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            \n",
    "            yield root, header, line\n",
    "\n",
    "def load_commonvoice(line_generator):\n",
    "        for root, header, line in line_generator:\n",
    "            output = dict(zip(header, line))\n",
    "            \n",
    "            # filename = line[1]\n",
    "            filename = output[\"path\"]\n",
    "            filename = os.path.join(root, \"clips\", filename)\n",
    "            waveform, sample_rate = torchaudio.load(filename)\n",
    "            \n",
    "            output[\"waveform\"] = waveform\n",
    "            output[\"sample_rate\"] = sample_rate\n",
    "\n",
    "            # client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "            # line.extend((waveform, sample_rate))\n",
    "            # yield line\n",
    "            \n",
    "            yield output\n",
    "\n",
    "g = load_commonvoice(iterate_commonvoice(dset_abs_path, tsv))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def iterate_commonvoice(root, tsv):\n",
    "    tsv = os.path.join(root, tsv)\n",
    "    with open(tsv) as tsv:\n",
    "        \n",
    "        header = next(tsv)\n",
    "        header = header.strip().split(\"\\t\")\n",
    "        \n",
    "        for line in tsv:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            output = dict(zip(header, line))\n",
    "            \n",
    "            # filename = line[1]\n",
    "            filename = output[\"path\"]\n",
    "            filename = os.path.join(root, \"clips\", filename)\n",
    "            waveform, sample_rate = torchaudio.load(filename)\n",
    "            \n",
    "            output[\"waveform\"] = waveform\n",
    "            output[\"sample_rate\"] = sample_rate\n",
    "\n",
    "            # client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "            # line.extend((waveform, sample_rate))\n",
    "            # yield line\n",
    "            \n",
    "            yield output\n",
    "\n",
    "g = iterate_commonvoice(dset_abs_path, tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
