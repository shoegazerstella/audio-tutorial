{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples of dataset:\n",
    "* [torchvision](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchaudio\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yesno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yesno\n",
    "# filename = \"waves_yesno.tar.gz\"\n",
    "# url = \"http://www.openslr.org/resources/1/\" + filename\n",
    "\n",
    "url = \"http://www.openslr.org/resources/1/waves_yesno.tar.gz\"\n",
    "filename = os.path.basename(url)\n",
    "root = \"/Users/vincentqb/yesnotest/\"\n",
    "\n",
    "inpath = root + filename\n",
    "dset_abs_path = root + \"waves_yesno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/vincentqb/yesnotest/waves_yesno.tar.gz\n"
     ]
    }
   ],
   "source": [
    "torchvision.datasets.utils.download_url(url, root)\n",
    "\n",
    "# torchvision.datasets.utils.extract_archive(inpath, root)  # FIXME no extraction with root\n",
    "torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_yesno(root):\n",
    "    for f in os.listdir(root):\n",
    "        if \".wav\" in f:\n",
    "            yield os.path.join(root, f)\n",
    "\n",
    "def load_yesno(file_generator):\n",
    "    for file in file_generator:\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "        label = os.path.basename(file).split(\".\", 1)[0].split(\"_\")\n",
    "    \n",
    "        yield label, waveform, sample_rate\n",
    "\n",
    "g = load_yesno(iterate_yesno(dset_abs_path))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def iterate_yesno(dset_abs_path):\n",
    "    for f in os.listdir(dset_abs_path):\n",
    "        if \".wav\" not in f:\n",
    "            continue\n",
    "    \n",
    "        full_path = os.path.join(dset_abs_path, f)\n",
    "        waveform, sample_rate = torchaudio.load(full_path)\n",
    "        label = os.path.basename(f).split(\".\", 1)[0].split(\"_\")\n",
    "        l = sig.size(1)\n",
    "    \n",
    "        yield label, waveform, sample_rate, l\n",
    "\n",
    "g = iterate_yesno(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vctk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"DS_10283_2651.zip\"\n",
    "filename2 = \"VCTK-Corpus.zip\"\n",
    "url = \"http://datashare.is.ed.ac.uk/download/\" + filename\n",
    "root = \"/Users/vincentqb/vctktest/\"\n",
    "\n",
    "inpath1 = root + filename1\n",
    "inpath2 = root + filename2\n",
    "dset_abs_path = root + \"VCTK-Corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "\n",
    "# torchvision.datasets.utils.extract_archive(inpath, root)  # FIXME no extraction with root\n",
    "torchvision.datasets.utils.extract_archive(inpath1)\n",
    "torchvision.datasets.utils.extract_archive(inpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_vctk(root):\n",
    "    folder_txt = os.path.join(root, \"txt/\")\n",
    "    folder_wav = os.path.join(root, \"wav48/\")\n",
    "    \n",
    "    for dp, _, fn in os.walk(folder_txt):\n",
    "        for f in fn:\n",
    "            if \".txt\" in f:\n",
    "                file_txt = os.path.join(dp, f)\n",
    "                base = os.path.basename(file_txt).split(\".\", 1)[0]\n",
    "                folder = base.split(\"_\")[0]\n",
    "                file_audio = os.path.join(folder_wav, folder, base) + \".wav\"\n",
    "            \n",
    "                yield base, file_txt, file_audio\n",
    "\n",
    "\n",
    "def load_vctk(file_generator):\n",
    "    for base, file_txt, file_audio in file_generator:\n",
    "            \n",
    "        with open(file_txt) as file_txt:\n",
    "            content = file_txt.readlines()[0]\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "\n",
    "        yield base, content, waveform, sample_rate\n",
    "\n",
    "\n",
    "g = load_vctk(iterate_vctk(dset_abs_path))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def iterate_vctk(root):\n",
    "    folder_txt = os.path.join(root, \"txt/\")\n",
    "    folder_wav = os.path.join(root, \"wav48/\")\n",
    "    \n",
    "    for dp, _, fn in os.walk(folder_txt):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "            \n",
    "            file_txt = os.path.join(dp, f)\n",
    "            with open(file_txt) as file_txt:\n",
    "                content = file_txt.readlines()[0]\n",
    "\n",
    "            \n",
    "            base = os.path.basename(f).split(\".\", 1)[0]\n",
    "            folder = base.split(\"_\")[0]\n",
    "            file_audio = os.path.join(folder_wav, folder, base) + \".wav\"\n",
    "            waveform, sample_rate = torchaudio.load(file_audio)\n",
    "            \n",
    "            yield base, content, waveform, sample_rate\n",
    "\n",
    "g = iterate_vctk(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p304_153',\n",
       " 'You need a trademark.',\n",
       " tensor([[0.0001, 0.0005, 0.0005,  ..., 0.0037, 0.0040, 0.0027]]),\n",
       " 48000)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2412-153954-0019',\n",
       " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0518e-05, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " 16000,\n",
       " 'BUT BY AND BY THEY CAME TO MY WATCH WHICH I HAD HIDDEN AWAY IN THE INMOST POCKET THAT I HAD AND HAD FORGOTTEN WHEN THEY BEGAN THEIR SEARCH')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.openslr.org/12\n",
    "# http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def compose(*funcs):\n",
    "    return lambda x: reduce(lambda f, g: g(f), list(funcs), x)\n",
    "\n",
    "\n",
    "class LibriSpeech(object):\n",
    "\n",
    "    url_base = \"http://www.openslr.org/resources/12/\"\n",
    "    url_extension = \".tar.gz\"\n",
    "    audio_extension = \".flac\"\n",
    "    text_extension = \".trans.txt\"\n",
    "\n",
    "    _selection = [\n",
    "        \"dev-clean\",\n",
    "        \"test-clean\",\n",
    "        \"test-other\",\n",
    "        \"train-clean-100\",\n",
    "        \"train-clean-360\",\n",
    "        \"train-other-500\"\n",
    "    ]\n",
    "    \n",
    "    in_archive_folder = \"LibriSpeech\"\n",
    "\n",
    "    def __init__(self, selection, root_path, extracted=True, shuffle=False):\n",
    "\n",
    "        if selection not in self._selection:\n",
    "            raise ValueError\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.selection = selection\n",
    "        self.extracted = extracted\n",
    "\n",
    "        self.url = self.url_base + self.selection + self.url_extension\n",
    "        \n",
    "        if shuffle:\n",
    "            c = compose(self.download, self.extract, self.walk, self.shuffle, self.load)\n",
    "        else:\n",
    "            c = compose(self.download, self.extract, self.walk, self.load)\n",
    "\n",
    "        # Initialize here or in __iter__\n",
    "        self._iterator = c([selection])\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self._iterator.__next__()\n",
    "        \n",
    "    def download(self, selections):\n",
    "        for selection in selections:\n",
    "            url = os.path.join(self.url_base, selection + self.url_extension)\n",
    "            # torchvision.datasets.utils.download_url(url, self.root_path)\n",
    "            yield selection\n",
    "    \n",
    "    def extract(self, selections):\n",
    "        for selection in selections:\n",
    "            archive_path = os.path.join(self.root_path, selection + self.url_extension)\n",
    "            # torchvision.datasets.utils.extract_archive(archive_path)\n",
    "            yield os.path.join(self.root_path, self.in_archive_folder, selection)\n",
    "\n",
    "    def walk(self, paths):\n",
    "        for path in paths:\n",
    "            for dp, dn, fn in os.walk(path):\n",
    "                for f in fn:\n",
    "                    if self.audio_extension in f:\n",
    "                        yield path, os.path.basename(f).split(\".\")[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle(generator):\n",
    "        generator = list(generator)\n",
    "        random.shuffle(generator)\n",
    "        for g in generator:\n",
    "            yield g\n",
    "        \n",
    "    def load(self, fileids):\n",
    "        for data_path, fileid in fileids:\n",
    "            folder1, folder2, file = fileid.split(\"-\")\n",
    "            file_text = folder1 + \"-\" + folder2 + self.text_extension\n",
    "            file_text = os.path.join(data_path, folder1, folder2, file_text)\n",
    "            file_audio = folder1 + \"-\"+ folder2 + \"-\" + file + self.audio_extension\n",
    "            filase_audio = os.path.join(data_path, folder1, folder2, file_audio)\n",
    "            waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "            found = False\n",
    "            for line in open(file_text):\n",
    "                fileid_text, content = line.strip().split(\" \", 1)\n",
    "                if fileid == fileid_text:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                from warnings import warn\n",
    "                warn(\"Audio file without translation: {}.\".format(fileid))\n",
    "                continue\n",
    "\n",
    "            yield fileid, waveform, sample_rate, content\n",
    "\n",
    "\n",
    "ls = LibriSpeech(\"dev-clean\", \"/Users/vincentqb/librispeechtest/\")\n",
    "next(ls) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# http://www.openslr.org/12\n",
    "# http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "\n",
    "class LibriSpeech(object):\n",
    "\n",
    "    url_base = \"http://www.openslr.org/resources/12/\"\n",
    "    url_extension = \".tar.gz\"\n",
    "    audio_extension = \".flac\"\n",
    "    text_extension = \".trans.txt\"\n",
    "\n",
    "    _selection = [\n",
    "        \"dev-clean\",\n",
    "        \"test-clean\",\n",
    "        \"test-other\",\n",
    "        \"train-clean-100\",\n",
    "        \"train-clean-360\",\n",
    "        \"train-other-500\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, selection, root_path, extracted=False):\n",
    "        if selection not in self._selection:\n",
    "            raise ValueError\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.selection = selection\n",
    "        self.extracted = extracted\n",
    "\n",
    "        self.url = self.url_base + self.selection + self.url_extension\n",
    "        self.data_path = os.path.join(self.root_path, \"LibriSpeech\", self.selection)\n",
    "        \n",
    "        # self._iter = self._walk_and_load()\n",
    "        self._iter = self._load(self._walk())\n",
    "        \n",
    "    def download_and_extract(self):\n",
    "        inpath = self.root_path + self.selection + self.url_extension\n",
    "        torchvision.datasets.utils.download_url(self.url, self.root_path)\n",
    "        torchvision.datasets.utils.extract_archive(inpath)\n",
    "        self.extracted = True\n",
    "\n",
    "    def _download(self):\n",
    "        torchvision.datasets.utils.download_url(self.url, self.root_path)\n",
    "        yield self.root_path + self.selection + self.url_extension\n",
    "    \n",
    "    def _extract(self, inpath):\n",
    "        torchvision.datasets.utils.extract_archive(inpath)\n",
    "        self.extracted = True\n",
    "        yield os.path.join(self.root_path, \"LibriSpeech\", self.selection)\n",
    "\n",
    "    def _walk_and_load(self):\n",
    "\n",
    "        while not self.extracted:\n",
    "            from warnings import warn\n",
    "            warn(\"Data not extracted\")\n",
    "            yield None\n",
    "\n",
    "        for dp, dn, fn in os.walk(self.data_path):\n",
    "            for f in fn:\n",
    "                if text_extension in f:\n",
    "                    fp = os.path.join(dp, f)\n",
    "                    for line in open(fp):\n",
    "                        fileid, content = line.strip().split(\" \", 1)\n",
    "                        audio = os.path.join(dp, fileid) + self.audio_extension\n",
    "                        waveform, sample_rate = torchaudio.load(audio)\n",
    "                        yield fileid, waveform, sample_rate, content\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self._iter.__next__()\n",
    "\n",
    "    def _walk2(self):\n",
    "\n",
    "        while not self.extracted:\n",
    "            from warnings import warn\n",
    "            warn(\"Data not extracted\")\n",
    "            yield None\n",
    "\n",
    "        for dp, dn, fn in os.walk(self.data_path):\n",
    "            for f in fn:\n",
    "                if self.text_extension in f:\n",
    "                    fp = os.path.join(dp, f)\n",
    "                    for line in open(fp):\n",
    "                        fileid, _ = line.strip().split(\" \", 1)\n",
    "                        yield fileid\n",
    "\n",
    "    def _walk(self):\n",
    "\n",
    "        while not self.extracted:\n",
    "            from warnings import warn\n",
    "            warn(\"Data not extracted\")\n",
    "            yield None\n",
    "\n",
    "        for dp, dn, fn in os.walk(self.data_path):\n",
    "            for f in fn:\n",
    "                if self.audio_extension in f:\n",
    "                    yield os.path.basename(f).split(\".\")[0]\n",
    "                    \n",
    "    def _load(self, fileid_generator):\n",
    "        for fileid in fileid_generator:\n",
    "            folder1, folder2, file = fileid.split(\"-\")\n",
    "            file_text = (\n",
    "                os.path.join(self.data_path, folder1, folder2, folder1)\n",
    "                + \"-\" + folder2 + self.text_extension\n",
    "            )\n",
    "            file_audio = (\n",
    "                os.path.join(self.data_path, folder1, folder2, folder1)\n",
    "                + \"-\"+ folder2 + \"-\" + file + self.audio_extension\n",
    "            )\n",
    "            waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "            found = False\n",
    "            for line in open(file_text):\n",
    "                fileid_text, content = line.strip().split(\" \", 1)\n",
    "                if fileid == fileid_text:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                raise Error\n",
    "\n",
    "            yield fileid, waveform, sample_rate, content\n",
    "\n",
    "g = load_librispeech(iterate_librispeech(dset_abs_path))\n",
    "\n",
    "\n",
    "ls = LibriSpeech(\"dev-clean\", \"/Users/vincentqb/librispeechtest/\")\n",
    "ls.extracted = True\n",
    "next(ls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Cache:\n",
    "    def __init__(self, generator, location):\n",
    "        self.generator = generator\n",
    "        self.location = location\n",
    "\n",
    "        self._id = id(self)\n",
    "        self._cache = []\n",
    "        self._internal_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._internal_index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._internal_index < len(self):\n",
    "            item = self[self._internal_index]\n",
    "        else:\n",
    "            item = next(self.generator)\n",
    "        \n",
    "            file = str(self._id) + \"-\" + str(len(self))\n",
    "            file = os.path.join(self.location, file)\n",
    "            self._cache.append(file)\n",
    "        \n",
    "            os.makedirs(self.location, exist_ok=True)\n",
    "            with open(file, 'wb') as file:\n",
    "                pickle.dump(item, file)\n",
    "\n",
    "        self._internal_index += 1\n",
    "        return item\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file = self._cache[index]\n",
    "        with open(file, 'rb') as file:\n",
    "            item = pickle.load(file)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for i in range(0,2):\n",
    "        yield i\n",
    "        \n",
    "cache = Cache(gen(), \"tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for c in cache:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# librispeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.openslr.org/12\n",
    "# http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "\n",
    "url_base = \"http://www.openslr.org/resources/12/\"\n",
    "url_extension = \".tar.gz\"\n",
    "\n",
    "selection = [\n",
    "    \"dev-clean\",\n",
    "    \"test-clean\",\n",
    "    \"test-clean\",\n",
    "    \"test-other\",\n",
    "    \"train-clean-100\",\n",
    "    \"train-clean-360\",\n",
    "    \"train-other-500\"\n",
    "]\n",
    "\n",
    "url = url_base + selection[0] + url_extension\n",
    "root = \"/Users/vincentqb/librispeechtest/\"\n",
    "\n",
    "filename = os.path.basename(url)\n",
    "inpath = root + filename\n",
    "\n",
    "base = filename.split(\".\")[0]\n",
    "dset_abs_path = root + \"LibriSpeech/\" + base + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "# torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iterate_librispeech(root):\n",
    "    for dp, dn, fn in os.walk(root):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "        \n",
    "            fp = os.path.join(dp, f)\n",
    "            for line in open(fp):\n",
    "                fileid, content = line.strip().split(\" \", 1)\n",
    "                audio = os.path.join(dp, fileid) + \".flac\"\n",
    "                waveform, sample_rate = torchaudio.load(audio)\n",
    "                yield fileid, waveform, sample_rate, content\n",
    "\n",
    "g = iterate_librispeech(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_librispeech(root):\n",
    "    for dp, dn, fn in os.walk(root):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "        \n",
    "            fp = os.path.join(dp, f)\n",
    "            for line in open(fp):\n",
    "                fileid, _ = line.strip().split(\" \", 1)\n",
    "                yield root, fileid\n",
    "\n",
    "def load_librispeech(file_generator):\n",
    "    for root, fileid in file_generator:\n",
    "        folder1, folder2, file = fileid.split(\"-\")\n",
    "        file_text = os.path.join(root, folder1, folder2, folder1) + \"-\" + folder2 + \".trans.txt\"\n",
    "        file_audio = os.path.join(root, folder1, folder2, folder1) + \"-\" + folder2 + \"-\" + file + \".flac\"\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "        found = False\n",
    "        for line in open(file_text):\n",
    "            fileid_text, content = line.strip().split(\" \", 1)\n",
    "            if fileid == fileid_text:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            raise Error\n",
    "\n",
    "        yield fileid, waveform, sample_rate, content\n",
    "\n",
    "g = load_librispeech(iterate_librispeech(dset_abs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2412-153954-0002',\n",
       " tensor([[-1.5259e-04, -2.1362e-04, -2.1362e-04,  ..., -3.0518e-05,\n",
       "           0.0000e+00, -3.0518e-05]]),\n",
       " 16000,\n",
       " 'THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommonVoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = \"https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/\"\n",
    "\n",
    "languages = {\n",
    "    \"tatar\": \"tt\",\n",
    "    \"english\": \"en\",\n",
    "    \"german\": \"de\",\n",
    "    \"french\": \"fr\",\n",
    "    \"welsh\": \"cy\",\n",
    "    \"breton\": \"br\",\n",
    "    \"chuvash\": \"cv\",\n",
    "    \"turkish\": \"tr\",\n",
    "    \"kyrgyz\": \"ky\",\n",
    "    \"irish\": \"ga-IE\",\n",
    "    \"kabyle\": \"kab\",\n",
    "    \"catalan\": \"ca\",\n",
    "    \"taiwanese\": \"zh-TW\",\n",
    "    \"slovenian\": \"sl\",\n",
    "    \"italian\": \"it\",\n",
    "    \"dutch\": \"nl\",\n",
    "    \"hakha chin\": \"cnh\",\n",
    "    \"esperanto\": \"eo\",\n",
    "    \"estonian\": \"et\",\n",
    "    \"persian\": \"fa\",\n",
    "    \"basque\": \"eu\",\n",
    "    \"spanish\": \"es\",\n",
    "    \"chinese\": \"zh-CN\",\n",
    "    \"mongolian\": \"mn\",\n",
    "    \"sakha\": \"sah\",\n",
    "    \"dhivehi\": \"dv\",\n",
    "    \"kinyarwanda\": \"rw\",\n",
    "    \"swedish\": \"sv-SE\",\n",
    "    \"russian\": \"ru\",\n",
    "}\n",
    "\n",
    "url = web + languages[\"tatar\"] + \".tar.gz\"\n",
    "root = \"/Users/vincentqb/commonvoicetest/\"\n",
    "\n",
    "filename = os.path.basename(url)\n",
    "inpath = root + filename\n",
    "\n",
    "base = filename.split(\".\")[0]\n",
    "dset_abs_path = root\n",
    "tsv = \"train.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "# torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_commonvoice(root, tsv):\n",
    "    tsv = os.path.join(root, tsv)\n",
    "    with open(tsv) as tsv:\n",
    "        \n",
    "        header = next(tsv)\n",
    "        header = header.strip().split(\"\\t\")\n",
    "        \n",
    "        for line in tsv:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            \n",
    "            yield root, header, line\n",
    "\n",
    "def load_commonvoice(line_generator):\n",
    "        for root, header, line in line_generator:\n",
    "            output = dict(zip(header, line))\n",
    "            \n",
    "            # filename = line[1]\n",
    "            filename = output[\"path\"]\n",
    "            filename = os.path.join(root, \"clips\", filename)\n",
    "            waveform, sample_rate = torchaudio.load(filename)\n",
    "            \n",
    "            output[\"waveform\"] = waveform\n",
    "            output[\"sample_rate\"] = sample_rate\n",
    "\n",
    "            # client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "            # line.extend((waveform, sample_rate))\n",
    "            # yield line\n",
    "            \n",
    "            yield output\n",
    "\n",
    "g = load_commonvoice(iterate_commonvoice(dset_abs_path, tsv))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def iterate_commonvoice(root, tsv):\n",
    "    tsv = os.path.join(root, tsv)\n",
    "    with open(tsv) as tsv:\n",
    "        \n",
    "        header = next(tsv)\n",
    "        header = header.strip().split(\"\\t\")\n",
    "        \n",
    "        for line in tsv:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            output = dict(zip(header, line))\n",
    "            \n",
    "            # filename = line[1]\n",
    "            filename = output[\"path\"]\n",
    "            filename = os.path.join(root, \"clips\", filename)\n",
    "            waveform, sample_rate = torchaudio.load(filename)\n",
    "            \n",
    "            output[\"waveform\"] = waveform\n",
    "            output[\"sample_rate\"] = sample_rate\n",
    "\n",
    "            # client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "            # line.extend((waveform, sample_rate))\n",
    "            # yield line\n",
    "            \n",
    "            yield output\n",
    "\n",
    "g = iterate_commonvoice(dset_abs_path, tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '11d5e99f7bd5b4f8492a06bb1ec22aa9110bba6ea9918f2a9adec05d686304d568ab7063daf8915d3fccfb4dd44b81646bd13a33ca130ac4014560bba4c2db0b',\n",
       " 'path': 'common_voice_tt_17343438.mp3',\n",
       " 'sentence': 'Баш өсте, хан хәзрәтләре.',\n",
       " 'up_votes': '2',\n",
       " 'down_votes': '0',\n",
       " 'age': 'thirties',\n",
       " 'gender': 'male',\n",
       " 'waveform': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.3644e-06,\n",
       "          -1.7546e-06,  2.0936e-06]]),\n",
       " 'sample_rate': 48000}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
