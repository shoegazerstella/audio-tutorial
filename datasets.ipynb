{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchaudio\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yesno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yesno\n",
    "# filename = \"waves_yesno.tar.gz\"\n",
    "# url = \"http://www.openslr.org/resources/1/\" + filename\n",
    "\n",
    "url = \"http://www.openslr.org/resources/1/waves_yesno.tar.gz\"\n",
    "filename = os.path.basename(url)\n",
    "root = \"/Users/vincentqb/yesnotest/\"\n",
    "\n",
    "inpath = root + filename\n",
    "dset_abs_path = root + \"waves_yesno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/vincentqb/yesnotest/waves_yesno.tar.gz\n"
     ]
    }
   ],
   "source": [
    "torchvision.datasets.utils.download_url(url, root)\n",
    "\n",
    "# torchvision.datasets.utils.extract_archive(inpath, root)  # FIXME no extraction with root\n",
    "torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_yesno(dset_abs_path):\n",
    "    for f in os.listdir(dset_abs_path):\n",
    "        if \".wav\" not in f:\n",
    "            continue\n",
    "    \n",
    "        full_path = os.path.join(dset_abs_path, f)\n",
    "        waveform, sample_rate = torchaudio.load(full_path)\n",
    "        label = os.path.basename(f).split(\".\", 1)[0].split(\"_\")\n",
    "        l = sig.size(1)\n",
    "    \n",
    "        yield label, waveform, sample_rate, l\n",
    "\n",
    "g = iterate_yesno(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vctk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"DS_10283_2651.zip\"\n",
    "filename2 = \"VCTK-Corpus.zip\"\n",
    "url = \"http://datashare.is.ed.ac.uk/download/\" + filename\n",
    "root = \"/Users/vincentqb/vctktest/\"\n",
    "\n",
    "inpath1 = root + filename1\n",
    "inpath2 = root + filename2\n",
    "dset_abs_path = root + \"VCTK-Corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "\n",
    "# torchvision.datasets.utils.extract_archive(inpath, root)  # FIXME no extraction with root\n",
    "torchvision.datasets.utils.extract_archive(inpath1)\n",
    "torchvision.datasets.utils.extract_archive(inpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_vctk(root):\n",
    "    folder_txt = os.path.join(root, \"txt/\")\n",
    "    folder_wav = os.path.join(root, \"wav48/\")\n",
    "    \n",
    "    for dp, _, fn in os.walk(folder_txt):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "            \n",
    "            file_txt = os.path.join(dp, f)\n",
    "            with open(file_txt) as file_txt:\n",
    "                content = file_txt.readlines()[0]\n",
    "\n",
    "            \n",
    "            base = os.path.basename(f).split(\".\", 1)[0]\n",
    "            folder = base.split(\"_\")[0]\n",
    "            file_audio = os.path.join(folder_wav, folder, base) + \".wav\"\n",
    "            waveform, sample_rate = torchaudio.load(file_audio)\n",
    "            \n",
    "            yield base, content, waveform, sample_rate\n",
    "\n",
    "g = iterate_vctk(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p304_225',\n",
       " 'I see no reason for them to be.',\n",
       " tensor([[-0.0038, -0.0046, -0.0047,  ..., -0.0019, -0.0019, -0.0017]]),\n",
       " 48000)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# librispeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.openslr.org/12\n",
    "    \n",
    "# http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "# http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "# http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "url = \"http://www.openslr.org/resources/12/dev-clean.tar.gz\"\n",
    "root = \"/Users/vincentqb/librispeechtest/\"\n",
    "\n",
    "filename = os.path.basename(url)\n",
    "inpath = root + filename\n",
    "\n",
    "base = filename.split(\".\")[0]\n",
    "dset_abs_path = root + \"LibriSpeech/\" + base + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "# torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iterate_librispeech(dset_abs_path):\n",
    "    for dp, dn, fn in os.walk(dset_abs_path):\n",
    "        for f in fn:\n",
    "            if \".txt\" not in f:\n",
    "                continue\n",
    "        \n",
    "            fp = os.path.join(dp, f)\n",
    "            for line in open(fp):\n",
    "                fileid, content = line.strip().split(\" \", 1)\n",
    "                flac = os.path.join(dp, fileid) + \".flac\"\n",
    "                waveform, sample_rate = torchaudio.load(flac)\n",
    "                yield fileid, waveform, sample_rate, content\n",
    "\n",
    "g = iterate_librispeech(dset_abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2412-153954-0000',\n",
       " tensor([[-3.0518e-05,  0.0000e+00,  3.0518e-05,  ..., -1.2207e-04,\n",
       "          -1.2207e-04, -9.1553e-05]]),\n",
       " 16000,\n",
       " 'SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommonVoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = \"https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/\"\n",
    "\n",
    "languages = {\n",
    "    \"tatar\": \"tt\",\n",
    "    \"english\": \"en\",\n",
    "    \"german\": \"de\",\n",
    "    \"french\": \"fr\",\n",
    "    \"welsh\": \"cy\",\n",
    "    \"breton\": \"br\",\n",
    "    \"chuvash\": \"cv\",\n",
    "    \"turkish\": \"tr\",\n",
    "    \"kyrgyz\": \"ky\",\n",
    "    \"irish\": \"ga-IE\",\n",
    "    \"kabyle\": \"kab\",\n",
    "    \"catalan\": \"ca\",\n",
    "    \"taiwanese\": \"zh-TW\",\n",
    "    \"slovenian\": \"sl\",\n",
    "    \"italian\": \"it\",\n",
    "    \"dutch\": \"nl\",\n",
    "    \"hakha chin\": \"cnh\",\n",
    "    \"esperanto\": \"eo\",\n",
    "    \"estonian\": \"et\",\n",
    "    \"persian\": \"fa\",\n",
    "    \"basque\": \"eu\",\n",
    "    \"spanish\": \"es\",\n",
    "    \"chinese\": \"zh-CN\",\n",
    "    \"mongolian\": \"mn\",\n",
    "    \"sakha\": \"sah\",\n",
    "    \"dhivehi\": \"dv\",\n",
    "    \"kinyarwanda\": \"rw\",\n",
    "    \"swedish\": \"sv-SE\",\n",
    "    \"russian\": \"ru\",\n",
    "}\n",
    "\n",
    "url = web + languages[\"tatar\"] + \".tar.gz\"\n",
    "root = \"/Users/vincentqb/commonvoicetest/\"\n",
    "\n",
    "filename = os.path.basename(url)\n",
    "inpath = root + filename\n",
    "\n",
    "base = filename.split(\".\")[0]\n",
    "dset_abs_path = root\n",
    "tsv = \"train.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.utils.download_url(url, root)\n",
    "# torchvision.datasets.utils.extract_archive(inpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_commonvoice(dset_abs_path, tsv):\n",
    "    f = os.path.join(dset_abs_path, tsv)\n",
    "    with open(f) as f:\n",
    "        next(f)  # skip header line\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            filename = os.path.join(dset_abs_path, \"clips\", line[1])\n",
    "            waveform, sample_rate = torchaudio.load(filename)\n",
    "\n",
    "            # client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "            line.extend((waveform, sample_rate))\n",
    "            yield line\n",
    "\n",
    "g = iterate_commonvoice(dset_abs_path, tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11d5e99f7bd5b4f8492a06bb1ec22aa9110bba6ea9918f2a9adec05d686304d568ab7063daf8915d3fccfb4dd44b81646bd13a33ca130ac4014560bba4c2db0b',\n",
       " 'common_voice_tt_17343438.mp3',\n",
       " 'Баш өсте, хан хәзрәтләре.',\n",
       " '2',\n",
       " '0',\n",
       " 'thirties',\n",
       " 'male',\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.3644e-06,\n",
       "          -1.7546e-06,  2.0936e-06]]),\n",
       " 48000]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
